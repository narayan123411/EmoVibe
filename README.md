# EmoVibe
EmoVibe: Personalized Emotion-Driven Music Recommendations

Project Leader: Narayan Raval

Project Member: Benjamin Claudius, Likhitha Potluri, Laxmi Naga Kavya Kolipaka

# Aim: 
The aim of this project is to develop an intelligent AI-driven music companion, EmoVibe, capable of curating and playing music in real-time based on the user's emotions and situational context. This system will leverage advanced emotion recognition and contextual understanding techniques to accurately identify a user's emotions, whether expressed through text or voice, and cater to their current situation, such as driving or relaxing. By analyzing emotional cues and situational information, EmoVibe will provide a seamless music experience that aligns with the user's emotional state and activities, enhancing their mood and overall well-being.

# Introduction: 

Introducing " EmoVibe " – your ultimate AI music buddy. It tunes in to how you feel and what you're up to, picking just the right music for you. Whether you're a bit down or on a road trip, EmoVibe picks music that fits your vibe. This clever friend is all about boosting your mood and changing how music makes you feel. It's like having your own personal DJ that understands you perfectly, making your music experience all about you.

# Visualization:

1. Data spread:
   ![image](https://github.com/narayan123411/EmoVibe/assets/53684708/937c918b-0d74-4378-a75f-f055f8e74215)

2. Data plot:
   ![image](https://github.com/narayan123411/EmoVibe/assets/53684708/7ec6d428-dccd-4c61-8d2d-9d658c4d6837)

3. Histogram Equlizer:
   ![image](https://github.com/narayan123411/EmoVibe/assets/53684708/7fbbf9d1-6c62-4d0e-9284-2ffd07ef85e4)

4. Normalization using the SMOTE Model:
   ![image](https://github.com/narayan123411/EmoVibe/assets/53684708/28aa71c1-2691-4549-b72f-93f78beb59e6)



# Conclusion:

An innovation in applying AI to personalize music encounters is the Emotion-Driven Music Companion project. The technology recommends music that strongly connects by automatically analyzing emotions and context and pairing them with user choices. Each user has a distinctive and captivating musical journey because of the seamless integration of sentiment analysis, contextual awareness, and genre choices. The potential for this initiative to completely transform how we interact with music as technology develops is limitless.

# Future Work:

•	Fine-tuned emotion Recognition: Continuously refining emotion recognition models for more precise results.
•	Global Reach: Expanding language and cultural support to cater to diverse audiences.
•	Real-Time Adaptation: Integrating real-time data for immediate context-based recommendations.
•	Learning and Feedback: Incorporating machine learning to learn from user interactions and enhance suggestions.
